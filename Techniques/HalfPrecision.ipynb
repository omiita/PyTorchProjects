{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Half_precision.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEdBHlVrbx4H",
        "colab_type": "text"
      },
      "source": [
        "### Caution\n",
        "\n",
        "Adam + Half Precision causes zero devision somewhere(eps might be the culprit...)\n",
        "\n",
        "* [Adam+Half Precision = NaNs?](https://discuss.pytorch.org/t/adam-half-precision-nans/1765/7)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEMsJoHDA7D3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install geffnet\n",
        "!pip uninstall tensorboard\n",
        "!pip install --force-reinstall tf-nightly-2.0-preview"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlAfi15IoRTy",
        "colab_type": "code",
        "outputId": "056c44fb-76f3-4940-b6a3-6dce03a318da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "!pip install --upgrade efficientnet-pytorch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: efficientnet-pytorch in /usr/local/lib/python3.6/dist-packages (0.6.1)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet-pytorch) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet-pytorch) (1.18.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpTlN07cBEbk",
        "colab_type": "code",
        "outputId": "3beb7050-eeef-4e80-c714-b7f7d4813acd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDVYf_cWBHy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip drive/My\\ Drive/cifar.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfgNOXEqBNlq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import glob\n",
        "import time\n",
        "import PIL\n",
        "import geffnet\n",
        "import datetime\n",
        "import os\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vnjvoh1jBOOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 512\n",
        "num_workers=4\n",
        "\n",
        "train_imgs = glob.glob('cifar/train/*.png')\n",
        "test_imgs = glob.glob('cifar/test/*.png')\n",
        "with open('cifar/labels.txt','r') as f:\n",
        "  l = f.readlines()\n",
        "label_idx_dict = {label.replace('\\n',''):idx for idx, label in enumerate(l)}\n",
        "\n",
        "transforms_dict = {'train':\n",
        "                   torchvision.transforms.Compose([\n",
        "                                                   torchvision.transforms.RandomResizedCrop(32),\n",
        "                                                   torchvision.transforms.RandomHorizontalFlip(),\n",
        "                                                   torchvision.transforms.ToTensor(),\n",
        "                                                   torchvision.transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "                   ])\n",
        "                   ,'test':torchvision.transforms.Compose([\n",
        "                                                           torchvision.transforms.ToTensor(),\n",
        "                                                           torchvision.transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "                   ])\n",
        "                   }\n",
        "\n",
        "class CIFAR10Dataset(torch.nn.Module):\n",
        "  def __init__(self,img_path, label_idx_dict, transforms=None):\n",
        "    self.img_path = img_path\n",
        "    self.label_idx_dict = label_idx_dict\n",
        "    self.transforms = transforms\n",
        "    self.length = len(self.img_path)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_p = self.img_path[idx]\n",
        "    img = PIL.Image.open(img_p)\n",
        "    label = img_p.split('/')[-1].split('_')[-1].replace('.png','')\n",
        "    label_idx =self.label_idx_dict[label]\n",
        "\n",
        "    if self.transforms:\n",
        "      img = self.transforms(img)\n",
        "\n",
        "    return img, label_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "train_ds = CIFAR10Dataset(train_imgs, label_idx_dict, transforms=transforms_dict['test'])\n",
        "test_ds = CIFAR10Dataset(test_imgs, label_idx_dict, transforms= transforms_dict['test'])\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size,shuffle=True, num_workers=num_workers)\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class tofp16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(tofp16, self).__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return input.half()\n",
        "\n",
        "def copy_in_params(net, params):\n",
        "    net_params = list(net.parameters())\n",
        "    for i in range(len(params)):\n",
        "        net_params[i].data.copy_(params[i].data)\n",
        "\n",
        "\n",
        "def set_grad(params, params_with_grad):\n",
        "\n",
        "    for param, param_w_grad in zip(params, params_with_grad):\n",
        "        if param.grad is None:\n",
        "            param.grad = torch.nn.Parameter(param.data.new().resize_(*param.data.size()))\n",
        "        param.grad.data.copy_(param_w_grad.grad.data)\n",
        "\n",
        "def BN_convert_float(module):\n",
        "    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
        "        module.float()\n",
        "    for child in module.children():\n",
        "        BN_convert_float(child)\n",
        "    return module\n",
        "\n",
        "\n",
        "def network_to_half(network):\n",
        "    return nn.Sequential(tofp16(), BN_convert_float(network.half()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaZY8UNyBOhz",
        "colab_type": "code",
        "outputId": "5041daab-25c1-4fc8-c2ea-2f5a52717186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr=2e-3\n",
        "num_epochs = 40\n",
        "# name = 'MixNet-M'\n",
        "name = 'ResNet50'\n",
        "# name = 'MobileNet-v2'\n",
        "# name='MnasNet-1'\n",
        "# name = 'EfficientNet-B0'\n",
        "# name = 'MobileNet-v3'\n",
        "\n",
        "if name=='ResNet50':\n",
        "  net = torchvision.models.resnet50(False)\n",
        "  net.fc = torch.nn.Linear(2048, 10)\n",
        "elif name=='MixNet-M':\n",
        "  net = geffnet.mixnet_m(True)\n",
        "  net.classifier = torch.nn.Linear(1536,10)\n",
        "elif name=='ResNet18':\n",
        "  net = torchvision.models.resnet18(True)\n",
        "  net.fc = torch.nn.Linear(512,10)\n",
        "elif name=='MobileNet-v2':\n",
        "  net=torchvision.models.mobilenet_v2(True)\n",
        "  net.classifier[1] = torch.nn.Linear(1280,10)\n",
        "elif name=='MnasNet-1':\n",
        "  net = torchvision.models.mnasnet1_0(False)\n",
        "  net.classifier[1] = torch.nn.Linear(1280,10)\n",
        "elif name=='EfficientNet-B0':\n",
        "  net=EfficientNet.from_pretrained('efficientnet-b0')\n",
        "  net._fc = torch.nn.Linear(1280,10)\n",
        "# elif name=='MobileNet-v3':\n",
        "#   net = MobileNetV3_Large()\n",
        "#   weights = torch.load('mobilenetv3/mbv3_large.old.pth.tar')\n",
        "#   weights = OrderedDict([(key.replace('module.',''),value) for key,value in weights['state_dict'].items()])\n",
        "#   net.load_state_dict(weights)\n",
        "#   net.linear4 = torch.nn.Linear(1280,10)\n",
        "\n",
        "net = network_to_half(net)\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(),lr=lr,eps=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available else 'cpu'\n",
        "torch.backends.cudnn.benchmark=False\n",
        "net.to(device)\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afi0EQE6PErC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
        "cur_time = str(t.month).zfill(2)+str(t.day).zfill(2) + str(t.hour).zfill(2)+str(t.minute).zfill(2)+str(t.second).zfill(2)\n",
        "\n",
        "train_log_dir = os.path.join('logs/tensorboard/train',name,cur_time)\n",
        "test_log_dir = os.path.join('logs/tensorboard/test',name,cur_time)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-VWeR9BxdFs",
        "colab_type": "code",
        "outputId": "88dee988-2b11-4d61-928d-c357f10eccba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3sfiJm_czSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"logs.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZN0VwscINxR",
        "colab_type": "code",
        "outputId": "f2d490dd-3269-4e5a-e64b-d52a61bdd7b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('START:',name)\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  cur_lr = scheduler.get_lr()[0]\n",
        "  epoch_losses = 0.\n",
        "  epoch_corrects = 0.\n",
        "  epoch_imgs = 0.\n",
        "\n",
        "  since=time.time()\n",
        "\n",
        "  net.train()\n",
        "  for imgs,labels in train_dl:\n",
        "    imgs,labels = imgs.to(device),labels.to(device)\n",
        "    epoch_imgs += imgs.size(0)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(imgs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_losses += loss.item() * imgs.size(0)\n",
        "    epoch_corrects += sum(outputs.argmax(1) == labels).item()\n",
        "\n",
        "  l = epoch_losses / epoch_imgs\n",
        "  a = epoch_corrects / epoch_imgs\n",
        "  print('Epoch {}: Loss {:.4f} Acc: {:.4f} lr:{:.4f} Time:{:.2f}'.format(epoch, l, a, cur_lr, time.time()-since))\n",
        "\n",
        "  with SummaryWriter(train_log_dir) as writer:\n",
        "    writer.add_scalar('loss',l,epoch)\n",
        "    writer.add_scalar('acc',a,epoch)\n",
        "\n",
        "\n",
        "  val_losses = 0.\n",
        "  val_corrects = 0.\n",
        "  val_imgs = 0.\n",
        "\n",
        "  net.eval()\n",
        "  for (imgs, labels) in test_dl:\n",
        "    imgs,labels = imgs.to(device), labels.to(device)\n",
        "    val_imgs += imgs.size(0)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      outputs = net(imgs)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "    val_losses += loss.item() * imgs.size(0)\n",
        "    val_corrects+= sum(outputs.argmax(1) == labels).item()\n",
        "\n",
        "  l = val_losses / val_imgs\n",
        "  a = val_corrects / val_imgs\n",
        "\n",
        "  print('Val: Loss: {:.4f} Acc: {:.4f}'.format(l, a))\n",
        "  with SummaryWriter(test_log_dir) as writer:\n",
        "    writer.add_scalar('loss', l, epoch)\n",
        "    writer.add_scalar('acc',a,epoch)\n",
        "\n",
        "  scheduler.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "START: ResNet50\n",
            "Epoch 1: Loss 2.3506 Acc: 0.2495 lr:0.0020 Time:25.61\n",
            "Val: Loss: 3.1850 Acc: 0.3342\n",
            "Epoch 2: Loss 1.9481 Acc: 0.3644 lr:0.0020 Time:25.46\n",
            "Val: Loss: 4.4643 Acc: 0.3768\n",
            "Epoch 3: Loss 1.7414 Acc: 0.4256 lr:0.0020 Time:25.41\n",
            "Val: Loss: 1.4849 Acc: 0.4517\n",
            "Epoch 4: Loss 1.5125 Acc: 0.4883 lr:0.0020 Time:25.52\n",
            "Val: Loss: 1.5513 Acc: 0.4967\n",
            "Epoch 5: Loss 1.3919 Acc: 0.5270 lr:0.0020 Time:25.56\n",
            "Val: Loss: 1.7173 Acc: 0.5176\n",
            "Epoch 6: Loss 1.3912 Acc: 0.5499 lr:0.0019 Time:25.68\n",
            "Val: Loss: 1.3727 Acc: 0.5064\n",
            "Epoch 7: Loss 1.3906 Acc: 0.5305 lr:0.0019 Time:25.80\n",
            "Val: Loss: 1.4162 Acc: 0.5259\n",
            "Epoch 8: Loss 1.2528 Acc: 0.5883 lr:0.0019 Time:25.75\n",
            "Val: Loss: 1.2014 Acc: 0.5764\n",
            "Epoch 9: Loss 1.1227 Acc: 0.6246 lr:0.0018 Time:25.55\n",
            "Val: Loss: 1.8836 Acc: 0.5990\n",
            "Epoch 10: Loss 0.9879 Acc: 0.6803 lr:0.0018 Time:25.53\n",
            "Val: Loss: 1.1270 Acc: 0.6054\n",
            "Epoch 11: Loss 0.8550 Acc: 0.7129 lr:0.0017 Time:25.91\n",
            "Val: Loss: 1.5964 Acc: 0.6166\n",
            "Epoch 12: Loss 0.8386 Acc: 0.7386 lr:0.0016 Time:25.63\n",
            "Val: Loss: 2.0164 Acc: 0.6396\n",
            "Epoch 13: Loss 0.9430 Acc: 0.6946 lr:0.0016 Time:25.83\n",
            "Val: Loss: 1.8951 Acc: 0.5755\n",
            "Epoch 14: Loss 0.8836 Acc: 0.6943 lr:0.0015 Time:26.03\n",
            "Val: Loss: 1.1953 Acc: 0.6315\n",
            "Epoch 15: Loss 0.7157 Acc: 0.7601 lr:0.0015 Time:25.73\n",
            "Val: Loss: 1.0943 Acc: 0.6480\n",
            "Epoch 16: Loss 0.5941 Acc: 0.8039 lr:0.0014 Time:25.70\n",
            "Val: Loss: 1.9932 Acc: 0.6215\n",
            "Epoch 17: Loss 0.7302 Acc: 0.7708 lr:0.0013 Time:25.73\n",
            "Val: Loss: 1.0639 Acc: 0.6635\n",
            "Epoch 18: Loss 0.5047 Acc: 0.8402 lr:0.0012 Time:26.04\n",
            "Val: Loss: 2.3243 Acc: 0.6613\n",
            "Epoch 19: Loss 0.4231 Acc: 0.8811 lr:0.0012 Time:25.47\n",
            "Val: Loss: 1.6290 Acc: 0.6588\n",
            "Epoch 20: Loss 0.4234 Acc: 0.8637 lr:0.0011 Time:25.99\n",
            "Val: Loss: 1.5455 Acc: 0.6699\n",
            "Epoch 21: Loss 0.2270 Acc: 0.9283 lr:0.0010 Time:25.74\n",
            "Val: Loss: 1.7029 Acc: 0.6719\n",
            "Epoch 22: Loss 0.2475 Acc: 0.9246 lr:0.0009 Time:25.46\n",
            "Val: Loss: 1.8346 Acc: 0.6694\n",
            "Epoch 23: Loss 0.1693 Acc: 0.9537 lr:0.0008 Time:25.26\n",
            "Val: Loss: 1.9348 Acc: 0.6669\n",
            "Epoch 24: Loss 0.1337 Acc: 0.9669 lr:0.0008 Time:25.52\n",
            "Val: Loss: 1.8940 Acc: 0.6746\n",
            "Epoch 25: Loss 0.1205 Acc: 0.9664 lr:0.0007 Time:25.65\n",
            "Val: Loss: 1.8827 Acc: 0.6709\n",
            "Epoch 26: Loss 0.0940 Acc: 0.9725 lr:0.0006 Time:25.33\n",
            "Val: Loss: 2.0315 Acc: 0.6766\n",
            "Epoch 27: Loss 0.0417 Acc: 0.9881 lr:0.0005 Time:25.58\n",
            "Val: Loss: 2.2802 Acc: 0.6801\n",
            "Epoch 28: Loss 0.0267 Acc: 0.9927 lr:0.0005 Time:25.78\n",
            "Val: Loss: 1.9946 Acc: 0.6890\n",
            "Epoch 29: Loss 0.0227 Acc: 0.9938 lr:0.0004 Time:25.55\n",
            "Val: Loss: 2.0985 Acc: 0.6868\n",
            "Epoch 30: Loss 0.0134 Acc: 0.9963 lr:0.0004 Time:25.58\n",
            "Val: Loss: 2.0956 Acc: 0.6876\n",
            "Epoch 31: Loss 0.0119 Acc: 0.9969 lr:0.0003 Time:25.76\n",
            "Val: Loss: 2.1415 Acc: 0.6885\n",
            "Epoch 32: Loss 0.0102 Acc: 0.9974 lr:0.0002 Time:25.87\n",
            "Val: Loss: 2.1650 Acc: 0.6853\n",
            "Epoch 33: Loss 0.0075 Acc: 0.9982 lr:0.0002 Time:26.09\n",
            "Val: Loss: 2.1147 Acc: 0.6892\n",
            "Epoch 34: Loss 0.0072 Acc: 0.9981 lr:0.0001 Time:26.13\n",
            "Val: Loss: 2.2431 Acc: 0.6869\n",
            "Epoch 35: Loss 0.0065 Acc: 0.9984 lr:0.0001 Time:26.10\n",
            "Val: Loss: 2.2573 Acc: 0.6872\n",
            "Epoch 36: Loss 0.0064 Acc: 0.9985 lr:0.0001 Time:26.00\n",
            "Val: Loss: 2.2062 Acc: 0.6870\n",
            "Epoch 37: Loss 0.0061 Acc: 0.9984 lr:0.0000 Time:25.71\n",
            "Val: Loss: 2.1350 Acc: 0.6875\n",
            "Epoch 38: Loss 0.0062 Acc: 0.9984 lr:0.0000 Time:25.95\n",
            "Val: Loss: 2.2225 Acc: 0.6872\n",
            "Epoch 39: Loss 0.0057 Acc: 0.9985 lr:0.0000 Time:26.34\n",
            "Val: Loss: 2.3881 Acc: 0.6845\n",
            "Epoch 40: Loss 0.0061 Acc: 0.9984 lr:0.0000 Time:25.97\n",
            "Val: Loss: 2.2039 Acc: 0.6893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne48EHq-eoVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs/tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KP-fNa9x5Yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}